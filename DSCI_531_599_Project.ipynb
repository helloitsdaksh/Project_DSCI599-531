{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "11H3g0lUyczhSK4i-ObYzPPbBqAU2LXHd",
      "authorship_tag": "ABX9TyNptDEoVXM4kKLzDSYgY/j9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helloitsdaksh/Project_DSCI599-531/blob/main/DSCI_531_599_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyFxI7tUkmW-",
        "outputId": "979673f2-7b81-4bab-9de4-0e8d89d13283"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CDQknVA-kcQf"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import TargetEncoder\n",
        "import optuna\n",
        "import os\n",
        "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FEMALE_POP = 0.536\n",
        "FEMALE_CAMPAIGN_POP = 0.392619\n",
        "MALE_POP = 0.464\n",
        "MALE_CAMPAIGN_POP = 0.607381\n",
        "FEMALE_RATIO = FEMALE_POP / FEMALE_CAMPAIGN_POP\n",
        "MALE_RATIO = MALE_POP / MALE_CAMPAIGN_POP"
      ],
      "metadata": {
        "id": "PgXYVVtfkhkl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZa4pz7Vl63a",
        "outputId": "0ee4d32a-267a-4875-a0ed-343adf39893a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------\n",
        "# Data utilities\n",
        "--------------------------------------------------------------"
      ],
      "metadata": {
        "id": "w_wLgJyWxBDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset\n",
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
        "\n",
        "def load_data(\n",
        "\t\tnrows: int = None,\n",
        "\t\tfilename: str = \"fairjob.csv.gz\"\n",
        "\t\t):\n",
        "\t\"\"\"\n",
        "\tData loader for FairJob dataset.\n",
        "\n",
        "\tArgs:\n",
        "\t\tnrows (int): How many rows to load for np.loadtxt. Defaults to None.\n",
        "\t\tfilename (str): Name of data file located in data/. Defaults to \"fairjob.csv.gz\".\n",
        "\n",
        "\tReturns:\n",
        "\t\tX (numpy.ndarray): (n_data, n_features)\n",
        "\t\tclick (np.ndarray): (n_data,)\n",
        "\t\tprotected_attribute (numpy.ndarray): (n_data,)\n",
        "\t\tsenior (numpy.ndarray): (n_data,)\n",
        "\t\tdisplayrandom (numpy.ndarray): (n_data,)\n",
        "\t\trank (numpy.ndarray): (n_data,)\n",
        "\t\tcategorical_features_cardinalities (dict): categorical features cardinalities\n",
        "\t\"\"\"\n",
        "\n",
        "\tdata = np.loadtxt((filename), skiprows=1, delimiter=\",\", max_rows=nrows)\n",
        "\tclick_idx = 0\n",
        "\tprotected_attribute_idx = 1\n",
        "\tsenior_idx = 2\n",
        "\tdisplayrandom_idx = 3\n",
        "\trank_idx = 4\n",
        "\tX = data[:, 5:]\n",
        "\tn_cat_cols = np.sum(X.mean(axis=0) > 1e-1)\n",
        "\tcategorical_features_idx = np.arange(0, n_cat_cols)\n",
        "\tcategorical_features_cardinalities = dict()\n",
        "\n",
        "\t# counting unique tokens per categorical variable\n",
        "\t# and renumbering them from 0\n",
        "\tfor dim in range(len(categorical_features_idx)):\n",
        "\t\trenumber_dict = dict()\n",
        "\t\tvalues = np.unique(X[:, dim])\n",
        "\t\tcategorical_features_cardinalities[dim] = len(values)\n",
        "\t\tfor i, v in enumerate(values):\n",
        "\t\t\trenumber_dict[v] = i\n",
        "\t\tfor i in range(len(X)):\n",
        "\t\t\tX[i, dim] = renumber_dict[X[i, dim]]\n",
        "\n",
        "\treturn (\n",
        "\t\tX,\n",
        "\t\tdata[:, click_idx],\n",
        "\t\tdata[:, protected_attribute_idx],\n",
        "\t\tdata[:, senior_idx],\n",
        "\t\tdata[:, displayrandom_idx],\n",
        "\t\tdata[:, rank_idx],\n",
        "\t\tcategorical_features_cardinalities,\n",
        "\t\t)\n",
        "\n",
        "class JobDataset(Dataset):\n",
        "\t\"\"\"\n",
        "\tClass collecting the variables of the data necessary for batch generation.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self, X, y, protected_attribute, fair_indicator):\n",
        "\t\tself.X = X\n",
        "\t\tself.y = y\n",
        "\t\tself.protected_attribute = protected_attribute\n",
        "\t\tif fair_indicator is None:\n",
        "\t\t\tself.fair_indicator = torch.ones_like(y).to(torch.int).to(y.device)\n",
        "\t\telse:\n",
        "\t\t\tself.fair_indicator = fair_indicator\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.y)\n",
        "\n",
        "\tdef get_target(self):\n",
        "\t\treturn self.y\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\treturn self.X[idx], self.y[idx], self.protected_attribute[idx], self.fair_indicator[idx]\n",
        "\n",
        "def batch_loader(dataset: JobDataset, batch_size: int):\n",
        "\t\"\"\"\n",
        "\tFactory for batch data loader with weighted random sampling for addressing class imbalance.\n",
        "\n",
        "\tArgs:\n",
        "\t\tdataset (JobDataset): Training data\n",
        "\t\tbatch_size (int): Batch size\n",
        "\n",
        "\tReturns:\n",
        "\t\tDataLoader\n",
        "\t\"\"\"\n",
        "\n",
        "\tclass_counts = torch.bincount(dataset.get_target())\n",
        "\tclass_weights = 1.0 / class_counts.float()\n",
        "\t# Create weights for each sample in the dataset\n",
        "\tsample_weights = class_weights[dataset.get_target()]\n",
        "\tsample_weights = sample_weights.detach().cpu().numpy()\n",
        "\n",
        "\tsampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\treturn DataLoader(dataset=dataset, batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "\n",
        "def train_test_split(\n",
        "\t\tX, y, protected_attribute, is_senior, displayrandom, rank, train_fraction: float = 0.8\n",
        "\t\t):\n",
        "\t\"\"\"\n",
        "\tRandom split of data in training and test sets.\n",
        "\n",
        "\tArgs:\n",
        "\t\tX: Features\n",
        "\t\ty: Target labels\n",
        "\t\tprotected_attribute: Protected attribute\n",
        "\t\tis_senior: Flag for senior ads.\n",
        "\t\tdisplayrandom: Flag for ads with random display order in the banner.\n",
        "\t\trank: Ads rank in the banner.\n",
        "\t\ttrain_fraction (float): Fraction for training data. Defaults to 0.8.\n",
        "\n",
        "\tReturns:\n",
        "\t\tX_train,\n",
        "\t\tX_test,\n",
        "\t\ty_train,\n",
        "\t\ty_test,\n",
        "\t\tprotected_attribute_train,\n",
        "\t\tprotected_attribute_test,\n",
        "\t\tis_senior_train,\n",
        "\t\tis_senior_test,\n",
        "\t\tdisplayrandom_train,\n",
        "\t\tdisplayrandom_test\n",
        "\t\trank_train,\n",
        "\t\trank_test\n",
        "\t\"\"\"\n",
        "\n",
        "\tcut = int(len(X) * train_fraction * 100 // 100)\n",
        "\tX_train = X[:cut, :]\n",
        "\tX_test = X[cut:, :]\n",
        "\ty_train = y[:cut]\n",
        "\ty_test = y[cut:]\n",
        "\tprotected_attribute_train = protected_attribute[:cut]\n",
        "\tprotected_attribute_test = protected_attribute[cut:]\n",
        "\tis_senior_train = is_senior[:cut]\n",
        "\tis_senior_test = is_senior[cut:]\n",
        "\tdisplayrandom_train = displayrandom[:cut]\n",
        "\tdisplayrandom_test = displayrandom[cut:]\n",
        "\trank_train = rank[:cut]\n",
        "\trank_test = rank[cut:]\n",
        "\treturn (\n",
        "\t\tX_train,\n",
        "\t\tX_test,\n",
        "\t\ty_train,\n",
        "\t\ty_test,\n",
        "\t\tprotected_attribute_train,\n",
        "\t\tprotected_attribute_test,\n",
        "\t\tis_senior_train,\n",
        "\t\tis_senior_test,\n",
        "\t\tdisplayrandom_train,\n",
        "\t\tdisplayrandom_test,\n",
        "\t\trank_train,\n",
        "\t\trank_test,\n",
        "\t\t)"
      ],
      "metadata": {
        "id": "jFlm0h8MkskR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------\n",
        "# Models\n",
        "--------------------------------------------------------------"
      ],
      "metadata": {
        "id": "fa8wi-igxia1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyClassifier(nn.Module):\n",
        "\t\"\"\"\n",
        "\tClassifier based on single threshold for positive class probability.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self, start_p: float = 0.005):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.bias = nn.Parameter(Tensor([1 - start_p, start_p]))\n",
        "\t\tself.bias.requires_grad = True\n",
        "\t\tself.register_buffer(\"zero_const\", torch.zeros((1, 2)))\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\treturn self.zero_const.repeat(x.shape[0], 1) + self.bias\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn \"Dummy\"\n",
        "\n",
        "\n",
        "class MixedEmbedding(nn.Module):\n",
        "\t\"\"\"\n",
        "\tLayer for embedding categorical and continuous features for Logistic Regression.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(\n",
        "\t\t\tself,\n",
        "\t\t\tinput_dim: int,\n",
        "\t\t\tcategorical_features_cardinalities: dict,\n",
        "\t\t\tembedding_size: int = 10,\n",
        "\t\t\t):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs:\n",
        "\t\t\tinput_dim (int): dimension of input features\n",
        "\t\t\tcategorical_features_cardinalities (dict): cardinalities (values) for each categorical feature (column index in the data as key)\n",
        "\t\t\tembedding_size (int): Output size of the mixed embedding layer. Defaults to 10.\n",
        "\t\t\"\"\"\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.input_dim = input_dim\n",
        "\t\tself.embedding_size = embedding_size\n",
        "\t\tself.categorical_features_idx = np.array(\n",
        "\t\t\t[_ for _ in categorical_features_cardinalities.keys()]\n",
        "\t\t\t)\n",
        "\t\tself.numerical_features_idx = np.array(\n",
        "\t\t\t[_ for _ in range(input_dim) if _ not in self.categorical_features_idx]\n",
        "\t\t\t)\n",
        "\t\tself.embeddings = nn.ModuleList(\n",
        "\t\t\t[\n",
        "\t\t\t\tnn.Embedding(\n",
        "\t\t\t\t\tnum_embeddings=categorical_features_cardinalities[cat_feature_idx],\n",
        "\t\t\t\t\tembedding_dim=min(\n",
        "\t\t\t\t\t\tembedding_size,\n",
        "\t\t\t\t\t\tcategorical_features_cardinalities[cat_feature_idx],\n",
        "\t\t\t\t\t\t),\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\tfor cat_feature_idx in self.categorical_features_idx\n",
        "\t\t\t\t]\n",
        "\t\t\t)\n",
        "\t\tself.output_dimension = len(self.numerical_features_idx) + sum(\n",
        "\t\t\t[e.embedding_dim for e in self.embeddings]\n",
        "\t\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tcatx = x[:, self.categorical_features_idx].int()\n",
        "\t\tnumx = x[:, self.numerical_features_idx]\n",
        "\t\tembeddedx = torch.hstack(\n",
        "\t\t\t[self.embeddings[_](catx[:, _]) for _ in self.categorical_features_idx]\n",
        "\t\t\t)\n",
        "\t\tembeddedx = embeddedx.view(-1, self.output_dimension - len(self.numerical_features_idx))\n",
        "\t\treturn torch.hstack([embeddedx, numx])\n",
        "\n",
        "\tdef to(self, device):\n",
        "\t\tself.embeddings.to(device)\n",
        "\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "\t\"\"\"\n",
        "\tLogistic regression classifier.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(\n",
        "\t\t\tself,\n",
        "\t\t\tinput_dim: int,\n",
        "\t\t\tcategorical_features_cardinalities: dict,\n",
        "\t\t\tembedding_size: int,\n",
        "\t\t\t):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs:\n",
        "\t\t\tinput_dim (int): dimension of input features\n",
        "\t\t\tcategorical_features_cardinalities (dict): cardinalities (values) for each categorical feature (column index in the data as key)\n",
        "\t\t\tembedding_size (int): Output size of the mixed embedding layer.\n",
        "\t\t\"\"\"\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.mixed_embedding_layer = MixedEmbedding(\n",
        "\t\t\tinput_dim,\n",
        "\t\t\tcategorical_features_cardinalities,\n",
        "\t\t\tembedding_size=embedding_size,\n",
        "\t\t\t)\n",
        "\t\tself.weights = nn.Linear(\n",
        "\t\t\tin_features=self.mixed_embedding_layer.output_dimension, out_features=2\n",
        "\t\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\txx = self.mixed_embedding_layer(x)\n",
        "\t\treturn self.weights(xx)\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn \"LR\"\n",
        "\n",
        "\tdef to(self, device):\n",
        "\t\tself.mixed_embedding_layer.to(device)\n",
        "\t\tself.weights.to(device)"
      ],
      "metadata": {
        "id": "-vTkVEdlxztm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "# Learning routines\n",
        "--------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "jaish22oyKg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def l2_conditional_independence_penalty(\n",
        "\t\ty_hat: Tensor, y_true: Tensor, protected_attribute: Tensor, fair_indicator: Tensor, *kwars\n",
        "\t\t):\n",
        "\t\"\"\"\n",
        "\tImplementation of the fairness penalty based on Bechavod & Ligett - https://arxiv.org/abs/1707.00044.\n",
        "\tDifferently from the original proposal, it uses the squared discrepancies between\n",
        "\tthe unconditional values of FPR, FNR, TPR, TNR and their conditional values, for both protected attribute labels.\n",
        "\n",
        "\tArgs:\n",
        "\t\ty_hat (Tensor): Predicted probabilities for the two target labels. Dimensions: (n_data, 2)\n",
        "\t\ty_true (Tensor): True labels. Dimensions: (n_data,)\n",
        "\t\tprotected_attribute (Tensor): Protected attributed values. Dimensions: (n_data,)\n",
        "\t\tfair_indicator (Tensor): Indicator for observations to be included in the penalty computation. Dimensions: (n_data,)\n",
        "\n",
        "\tReturns:\n",
        "\t\tValue of the fairness penalty\n",
        "\t\"\"\"\n",
        "\n",
        "\tassert y_hat.shape[1] == 2\n",
        "\tsum_of_squares = Tensor([0.0]).to(y_hat.device)\n",
        "\n",
        "\ty_hat = y_hat[fair_indicator, :]\n",
        "\ty_true = y_true[fair_indicator]\n",
        "\tprotected_attribute = protected_attribute[fair_indicator]\n",
        "\tfor y_hat_dim in (0, 1):\n",
        "\t\ty_hat_col = y_hat[:, y_hat_dim]\n",
        "\t\tfor y_dim in (0, 1):\n",
        "\t\t\tif torch.sum(y_true == y_dim) == 0.0:  # no such label\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ty_hat_avg = torch.mean(y_hat_col[y_true == y_dim])\n",
        "\t\t\tfor a_dim in (0, 1):\n",
        "\t\t\t\tif (\n",
        "\t\t\t\t\t\ttorch.sum((y_true == y_dim) & (protected_attribute == a_dim)) == 0.0\n",
        "\t\t\t\t):  # no such label given attribute\n",
        "\t\t\t\t\ty_hat_cond_a_avg = torch.tensor(0.0)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\ty_hat_cond_a_avg = torch.mean(\n",
        "\t\t\t\t\t\ty_hat_col[(y_true == y_dim) & (protected_attribute == a_dim)]\n",
        "\t\t\t\t\t\t)\n",
        "\t\t\t\tsum_of_squares += (y_hat_avg - y_hat_cond_a_avg) ** 2\n",
        "\tpenalty = torch.sqrt(sum_of_squares)[0]\n",
        "\treturn penalty\n",
        "\n",
        "\n",
        "class Learner(object):\n",
        "\t\"\"\"\n",
        "\tGeneral class for learner.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(\n",
        "\t\t\tself,\n",
        "\t\t\tbase_model,\n",
        "\t\t\tdevice=\"cuda\",\n",
        "\t\t\tbasename: str = \"REGULAR\",\n",
        "\t\t\tscheduler_step_size=30,\n",
        "\t\t\tscheduler_gamma=0.1,\n",
        "\t\t\t**optimizer_options\n",
        "\t\t\t):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs:\n",
        "\t\t\tbase_model: Base model class  (e.g., Dummy, LogisticRegression)\n",
        "\t\t\tdevice (str): Device for PyTorch. Defaults to \"cuda\".\n",
        "\t\t\tbasename (str): Model name. Defaults to \"REGULAR\".\n",
        "\t\t\tscheduler_step_size (int): Step size parameter for learning rate scheduler. Defaults to 30.\n",
        "\t\t\tscheduler_gamma (float): Gamma parameter for learning rate scheduler. Defaults to 0.1.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tself.model = base_model\n",
        "\t\tself.model.ps_init = nn.Parameter(torch.randn(1), requires_grad=False)\n",
        "\t\tself.model.ps = nn.Parameter(self.model.ps_init.data, requires_grad=True)\n",
        "\t\tself.basename = basename\n",
        "\t\tself.loss = nn.CrossEntropyLoss()\n",
        "\t\tself.optimizer = torch.optim.Adam(self.model.parameters(), **optimizer_options)\n",
        "\t\tself.scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "\t\t\tself.optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma\n",
        "\t\t\t)\n",
        "\t\tself.device = device\n",
        "\t\tself.model.to(device)\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn self.basename + \" \" + str(self.model).split(\"(\")[0]\n",
        "\n",
        "\tdef fit(\n",
        "\t\t\tself,\n",
        "\t\t\tx: Tensor,\n",
        "\t\t\ty: Tensor,\n",
        "\t\t\ta: Tensor,\n",
        "\t\t\tbatch_size=1024,\n",
        "\t\t\tpenalty_fun=None,\n",
        "\t\t\tpenalty_multiplier: float = 0.1,\n",
        "\t\t\tfair_indicator: Tensor = None,\n",
        "\t\t\t):\n",
        "\t\t\"\"\"\n",
        "\t\tFit function (single epoch).\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tx (Tensor): Training features\n",
        "\t\t\ty (Tensor): Training target labels\n",
        "\t\t\ta (Tensor): Training protected attribute\n",
        "\t\t\tbatch_size (int): Batch size. Defaults to 1024.\n",
        "\t\t\tpenalty_fun : Additional penalty function to include fairness penalty. Defaults to None.\n",
        "\t\t\tpenalty_multiplier (float): Multiplier for additional penalty function. Defaults to 0.1.\n",
        "\t\t\tfair_indicator (Tensor):  Indicator for observations to be included in the penalty computation. Defaults to None.\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tLoss value\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tloss_value = 0\n",
        "\n",
        "\t\tdata_train = JobDataset(x, y, a, fair_indicator)\n",
        "\t\tfor batch in batch_loader(data_train, batch_size=batch_size):\n",
        "\t\t\tx_b, y_b, a_b, fair_indicator_b = batch\n",
        "\t\t\to_b = x_b[:, 1]\n",
        "\t\t\tself.optimizer.zero_grad()\n",
        "\t\t\toutputs_b = self.model(x_b)\n",
        "\n",
        "\t\t\tloss_b = self.loss(outputs_b, y_b)\n",
        "\n",
        "\t\t\tif penalty_fun is not None:\n",
        "\t\t\t\tprobas_b = torch.softmax(outputs_b, dim=1)\n",
        "\t\t\t\tassert torch.max(probas_b) <= 1.0, torch.max(probas_b)\n",
        "\t\t\t\tassert torch.min(probas_b) >= 0.0, torch.min(probas_b)\n",
        "\t\t\t\tloss_b += penalty_multiplier * penalty_fun(\n",
        "\t\t\t\t\ty_hat=probas_b,\n",
        "\t\t\t\t\ty_true=y_b,\n",
        "\t\t\t\t\tprotected_attribute=a_b,\n",
        "\t\t\t\t\tfair_indicator=fair_indicator_b,\n",
        "\t\t\t\t\t)\n",
        "\n",
        "\t\t\tloss_b.backward()\n",
        "\t\t\tloss_value += loss_b.detach().cpu().numpy()\n",
        "\t\t\tself.optimizer.step()\n",
        "\n",
        "\t\treturn loss_value\n",
        "\n",
        "\tdef scheduler_step(self):\n",
        "\t\tself.scheduler.step()\n",
        "\n",
        "\tdef __call__(self, *args, **kwargs):\n",
        "\t\treturn self.model(*args, **kwargs)\n",
        "\n",
        "\tdef get_ps(self, *args, **kwargs):\n",
        "\t\treturn self.model.ps.data\n",
        "\n",
        "\tdef get_ps_init(self, *args, **kwargs):\n",
        "\t\treturn self.model.ps_init.data\n",
        "\n",
        "\tdef to(self, device: str):\n",
        "\t\tself.device = device\n",
        "\t\tself.model.to(device)\n",
        "\t\tself.loss.to(device)"
      ],
      "metadata": {
        "id": "s85aPFFNyOs1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "--------------------------------------------------------------------------------\n",
        "# Metrics\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rsQBLTRVyjqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def demographic_parity(predictions, protected_attribute, scope):\n",
        "\t\"\"\"\n",
        "\tFunction to compute demographic parity with respect to scope.\n",
        "\n",
        "\tArgs:\n",
        "\t\tpredictions: model predictions\n",
        "\t\tprotected_attribute: protected attribute values\n",
        "\t\tscope: indicator for scope\n",
        "\n",
        "\tReturns:\n",
        "\t   Demographic parity\n",
        "\t\"\"\"\n",
        "\n",
        "\tres = 0.0\n",
        "\tfor col in (0, 1):\n",
        "\t\tres += torch.abs(\n",
        "\t\t\ttorch.mean(predictions[(protected_attribute > 0) & (scope > 0)][:, col])\n",
        "\t\t\t- torch.mean(predictions[(protected_attribute <= 0) & (scope > 0)][:, col])\n",
        "\t\t\t)\n",
        "\treturn res / 2.0\n",
        "\n",
        "\n",
        "def utility(\n",
        "\t\ty_pred: Tensor,\n",
        "\t\ty: Tensor,\n",
        "\t\tprotected_attribute: Tensor,\n",
        "\t\timpressions: Tensor,\n",
        "\t\tdisplayrandom: Tensor,\n",
        "\t\t):\n",
        "\t\"\"\"\n",
        "\tClick utility function.\n",
        "\n",
        "\tArgs:\n",
        "\t\ty_pred (Tensor): Predicted probabilities for the two target labels. Dimensions (n_data, 2)\n",
        "\t\ty (Tensor): Target labels. Dimensions (n_data,)\n",
        "\t\tprotected_attribute (Tensor): Protected attribute. Dimensions (n_data,)\n",
        "\t\timpressions (Tensor): Impression_id. Dimensions (n_data,)\n",
        "\t\tdisplayrandom (Tensor): Flag for ads with random display order in the banner. Dimensions (n_data,)\n",
        "\n",
        "\tReturns:\n",
        "\t\tValue of the utility\n",
        "\t\"\"\"\n",
        "\n",
        "\t# Higher is better\n",
        "\tres = 0.0\n",
        "\tclick_col = 1\n",
        "\t# Subselect only data with randomized display\n",
        "\tmask = (displayrandom > 0)\n",
        "\ty_pred = y_pred[mask]\n",
        "\ty = y[mask]\n",
        "\tprotected_attribute = protected_attribute[mask]\n",
        "\timpressions = impressions[mask]\n",
        "\n",
        "\tfor impression in torch.unique(impressions):\n",
        "\t\ty_ranked = (torch.argsort(y_pred[impressions == impression,click_col]) + 1).to(torch.float)\n",
        "\t\ty_clicked = y[impressions == impression]\n",
        "\t\tclick_rank_impression = torch.mean(y_ranked * y_clicked)\n",
        "\n",
        "\t\tres += click_rank_impression\n",
        "\n",
        "\treturn res / (torch.unique(impressions)).size(dim=0)\n",
        "\n",
        "\n",
        "def utility_product(\n",
        "\t\ty_pred, y, protected_attribute, impressions, displayrandom, product, unbiased_ratio=False\n",
        "\t\t):\n",
        "\t\"\"\"\n",
        "\tProduct utility function.\n",
        "\n",
        "\tArgs:\n",
        "\t\ty_pred (Tensor): Predicted probabilities for the two target labels. Dimensions (n_data, 2)\n",
        "\t\ty (Tensor): Target labels. Dimensions (n_data,)\n",
        "\t\tprotected_attribute (Tensor): Protected attribute. Dimensions (n_data,)\n",
        "\t\timpressions (Tensor): Impression_id. Dimensions (n_data,)\n",
        "\t\tdisplayrandom (Tensor): Flag for ads with random display order in the banner. Dimensions (n_data,)\n",
        "\t\tunbiased_ratio (bool): True if the utility should be corrected with the data-population ratio of the protected attribute. Defaults to False.\n",
        "\n",
        "\tReturns:\n",
        "\t\tValue of the utility\n",
        "\t\"\"\"\n",
        "\n",
        "\tres = 0.0\n",
        "\tclick_col = 1\n",
        "\t# Subselect only data with randomized display\n",
        "\tmask = (displayrandom > 0)\n",
        "\ty_pred = y_pred[mask]\n",
        "\ty = y[mask]\n",
        "\tprotected_attribute = protected_attribute[mask]\n",
        "\timpressions = impressions[mask]\n",
        "\tproduct = product[mask]\n",
        "\n",
        "\t# Create rank probs for each impression\n",
        "\ty_ranked = torch.zeros_like(y,dtype=torch.float)\n",
        "\tfor impression in torch.unique(impressions):\n",
        "\t\ty_ranked[impressions == impression] = (torch.argsort(y_pred[impressions == impression,click_col]) + 1).to(torch.float)\n",
        "\n",
        "\tif unbiased_ratio:\n",
        "\t\tratio = (protected_attribute == 0) * FEMALE_RATIO + \\\n",
        "\t\t\t\t(protected_attribute == 1) * MALE_RATIO\n",
        "\telse:\n",
        "\t\tratio = torch.ones_like(protected_attribute, dtype=torch.float)\n",
        "\n",
        "\tfor prod in torch.unique(product):\n",
        "\t\tprod_mask = (product == prod)\n",
        "\t\tfor impression in torch.unique(impressions[prod_mask]):\n",
        "\t\t\tsize_impressions_prod = torch.unique(impressions[prod_mask]).shape[0]\n",
        "\t\t\timpression_prod_mask = (impressions == impression) & prod_mask # Not really necessary, each impression is for a specific product\n",
        "\t\t\ty_ranked_prod = y_ranked[impression_prod_mask]\n",
        "\t\t\ty_clicked_prod = y[impression_prod_mask]\n",
        "\n",
        "\t\t\tclick_rank_impression = (y_ranked_prod * ratio[impression_prod_mask]).dot(y_clicked_prod.to(torch.float))\n",
        "\t\t\tres += click_rank_impression/size_impressions_prod\n",
        "\n",
        "\treturn res/ torch.unique(product).shape[0]\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "\t\tres_pred_df: pd.DataFrame,\n",
        "\t\tresults_df: pd.DataFrame,\n",
        "\t\tname: str,\n",
        "\t\tl2_fair: float,\n",
        "\t\tfair_frac: float,\n",
        "\t\tsim: int,\n",
        "\t\tmodel,\n",
        "\t\tX_test: Tensor,\n",
        "\t\ty_test: Tensor,\n",
        "\t\tprotected_attribute_test: Tensor,\n",
        "\t\tis_senior_test: Tensor,\n",
        "\t\timpression_test: Tensor,\n",
        "\t\tdisplayrandom_test: Tensor,\n",
        "\t\tproduct_test: Tensor,\n",
        "\t\t):\n",
        "\t\"\"\"\n",
        "\tFunction for computing model evaluation metrics and save results.\n",
        "\n",
        "\tArgs:\n",
        "\t\tres_pred_df (pd.DataFrame): DataFrame for saving model predictions.\n",
        "\t\tresults_df (pd.DataFrame): DataFrame for saving model metrics.\n",
        "\t\tname (str): Model name as used in DataFrame index.\n",
        "\t\tl2_fair (float): Fairness penalty multiplier. Use None if without penalty.\n",
        "\t\tfair_frac (float): Fraction of data used to compute the fairness penalty. Use None if without penalty.\n",
        "\t\tsim (int): Simulation index.\n",
        "\t\tmodel: Model to use for predictions.\n",
        "\t\tX_test (Tensor): Test features.\n",
        "\t\ty_test (Tensor): Test target labels.\n",
        "\t\tprotected_attribute_test (Tensor): Test protected attribute.\n",
        "\t\tis_senior_test (Tensor): Test senior ads indicator.\n",
        "\t\timpression_test (Tensor): Test impression id.\n",
        "\t\tdisplayrandom_test (Tensor): Test displayrandom.\n",
        "\t\tproduct_test (Tensor): Test product id.\n",
        "\n",
        "\tReturns:\n",
        "\t\tres_pred_df: updated with new values. Note that results_df is modified in-place.\n",
        "\t\"\"\"\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\ty_pred = model(X_test)\n",
        "\t\tp = torch.softmax(y_pred, dim=1)\n",
        "\tif l2_fair is not None:\n",
        "\t\t# We save fair models\n",
        "\t\trows_index = (name,l2_fair,fair_frac,sim)\n",
        "\telse:\n",
        "\t\t# We save regular models\n",
        "\t\trows_index = (name,sim)\n",
        "\n",
        "\t# Saving prediction\n",
        "\tres_pred_df = pd.concat(\n",
        "\t\t[\n",
        "\t\t\tres_pred_df,\n",
        "\t\t\tpd.DataFrame(\n",
        "\t\t\t\t{\n",
        "\t\t\t\t\t\"prob_test\": p[:,1].detach().cpu().numpy(),\n",
        "\t\t\t\t\t\"y_test\": y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\"a_test\": protected_attribute_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\"s_test\": is_senior_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\"displayrandom_test\": displayrandom_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\"impression_id_test\": impression_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\"product_id_test\": product_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t).reset_index(names=\"obs_index\").assign(model=name,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tfairness_multiplier=l2_fair,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tfairness_fraction=fair_frac,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\titeration=sim),\n",
        "\t\t\t]\n",
        "\t\t)\n",
        "\n",
        "\tresults_df.loc[rows_index] = {\n",
        "\t\t\"NLLH\": nn.CrossEntropyLoss()(y_pred, y_test).item(),\n",
        "\t\t\"DP\": demographic_parity(p, protected_attribute_test, is_senior_test).item(),\n",
        "\t\t\"UTILITY\": utility(\n",
        "\t\t\tp, y_test, protected_attribute_test, impression_test, displayrandom_test\n",
        "\t\t\t).item(),\n",
        "\t\t\"UTILITY_PRODUCT\": utility_product(\n",
        "\t\t\tp, y_test, protected_attribute_test, impression_test, displayrandom_test, product_test, unbiased_ratio=False\n",
        "\t\t\t).item(),\n",
        "\t\t\"UTILITY_PRODUCT_FAIR\": utility_product(\n",
        "\t\t\tp, y_test, protected_attribute_test, impression_test, displayrandom_test, product_test, unbiased_ratio=True\n",
        "\t\t\t).item(),\n",
        "\t\t\"AU-ROC\": roc_auc_score(y_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\ty_score=p[:,1].detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\taverage='macro'),\n",
        "\t\t\"AVG-P-SCORE\": average_precision_score(y_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\t   y_score=p[:,1].detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\t   average='macro'),\n",
        "\t\t}\n",
        "\tprint(\n",
        "\t\t\"(%20s) NLLH: %.5f DP: %.5f UTILITY: %.5f UTILITY_P: %.5f UTILITY_P_FAIR: %.5f AU-ROC: %.5f AVG-P-SCORE: %.5f\"\n",
        "\t\t% (\n",
        "\t\t\tmodel,\n",
        "\t\t\tresults_df.loc[rows_index,'NLLH'],\n",
        "\t\t\tresults_df.loc[rows_index,'DP'],\n",
        "\t\t\tresults_df.loc[rows_index,'UTILITY'],\n",
        "\t\t\tresults_df.loc[rows_index,'UTILITY_PRODUCT'],\n",
        "\t\t\tresults_df.loc[rows_index,'UTILITY_PRODUCT_FAIR'],\n",
        "\t\t\tresults_df.loc[rows_index,'AU-ROC'],\n",
        "\t\t\tresults_df.loc[rows_index,'AVG-P-SCORE']\n",
        "\t\t\t)\n",
        "\t\t)\n",
        "\treturn res_pred_df\n",
        "\n",
        "\n",
        "def prediction_stats(model, X_test: Tensor, protected_attribute_test: Tensor):\n",
        "\t\"\"\"\n",
        "\tPrints the prediction statistics with respect to protected attribute.\n",
        "\n",
        "\tArgs:\n",
        "\t\tmodel: Model used for prediction\n",
        "\t\tX_test (Tensor): Test features.\n",
        "\t\tprotected_attribute_test (_type_): Test protected attribute.\n",
        "\t\"\"\"\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\ty_pred = model(X_test)\n",
        "\tres_fit_df = pd.DataFrame({'attribute': protected_attribute_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t   0: torch.softmax(y_pred,dim=1).detach().cpu().numpy()[:,0],\n",
        "\t\t\t\t\t\t\t   1: torch.softmax(y_pred,dim=1).detach().cpu().numpy()[:,1]})\n",
        "\tprint(res_fit_df.set_index('attribute').groupby('attribute').mean())\n",
        "\tprint(torch.softmax(y_pred,dim=1).detach().cpu().numpy()[0,:])\n",
        "\tprint('\\n')"
      ],
      "metadata": {
        "id": "JN01bomayqbX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "--------------------------------------------------------------------------------\n",
        "# Run Experiments\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "y1DwJhhsyt39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(args):\n",
        "\t# Copy the main execution logic of your script int(f\"Running experiment with settings: {args}\")\n",
        "\tN_TRAIN_EXAMPLES = 10**5\n",
        "\tDATA_SIZE = None  # None for all data\n",
        "\tsim = 0\n",
        "\tN_EPOCHS = 50\n",
        "\n",
        "\t# Seed for reproducibility\n",
        "\ttorch.manual_seed(43523)\n",
        "\tnp.random.seed(43523)\n",
        "\n",
        "\t# Check for MPS (Metal Performance Shaders) on macOS\n",
        "\tif torch.backends.mps.is_available():\n",
        "\t\tdevice = torch.device(\"mps\")  # Use Metal for PyTorch\n",
        "\t\txgb_device = \"cpu\"  # XGBoost does not support MPS yet, so use CPU\n",
        "\t\txgb_tree_method = \"hist\"  # Use histogram-based tree method for efficiency\n",
        "\telif torch.cuda.is_available():\n",
        "\t\tdevice = torch.device(\"cuda\")  # Use CUDA if available\n",
        "\t\txgb_device = \"cuda\"\n",
        "\t\txgb_tree_method = \"hist\"\n",
        "\telse:\n",
        "\t\tdevice = torch.device(\"cpu\")  # Fallback to CPU\n",
        "\t\txgb_device = \"cpu\"\n",
        "\t\txgb_tree_method = \"hist\"\n",
        "\n",
        "\tprint(f\"Using device: {device}\")\n",
        "\n",
        "\tif not os.path.exists((\"output\")):\n",
        "\t\tos.makedirs((\"output\"))\n",
        "\n",
        "\tif not os.path.exists((\"output/model_hyperparameters\")):\n",
        "\t\tos.makedirs((\"output/model_hyperparameters\"))\n",
        "\n",
        "\n",
        "\tbatch_size = args.batch\n",
        "\tl2_fair_multiplier = args.lambda_fair\n",
        "\tfair_fraction = args.data_frac\n",
        "\tn_trials = args.ntrial\n",
        "\n",
        "\t# Print setup\n",
        "\tprint(args)\n",
        "\tprint('Device: ' + str(device))\n",
        "\n",
        "\t# Name for saving results\n",
        "\targs.name = (\n",
        "\t\t\t\"_\"\n",
        "\t\t\t+ args.name\n",
        "\t\t\t+ \"_lambda\"\n",
        "\t\t\t+ str(args.lambda_fair)\n",
        "\t\t\t+ \"_frac\"\n",
        "\t\t\t+ str(args.data_frac)\n",
        "\t)\n",
        "\n",
        "\n",
        "\t# DataFrame for saving results\n",
        "\tres_pred_df = pd.DataFrame(\n",
        "\t\tcolumns=[\n",
        "\t\t\t\"model\",\n",
        "\t\t\t\"fairness_multiplier\",\n",
        "\t\t\t\"fairness_fraction\",\n",
        "\t\t\t\"obs_index\",\n",
        "\t\t\t\"prob_test\",\n",
        "\t\t\t\"y_test\",\n",
        "\t\t\t\"a_test\",\n",
        "\t\t\t\"s_test\",\n",
        "\t\t\t\"displayrandom_test\",\n",
        "\t\t\t\"impression_id_test\",\n",
        "\t\t\t\"product_id_test\",\n",
        "\t\t\t]\n",
        "\t\t)\n",
        "\n",
        "\t# Data loading and splitting\n",
        "\t(\n",
        "\t\tX,\n",
        "\t\ty,\n",
        "\t\tprotected_attribute,\n",
        "\t\tis_senior,\n",
        "\t\tdisplayrandom,\n",
        "\t\trank,\n",
        "\t\tcategorical_features_cardinalities,\n",
        "\t\t) = load_data(DATA_SIZE, args.data)\n",
        "\n",
        "\tX, y, protected_attribute, is_senior, displayrandom, rank = (\n",
        "\t\tTensor(X.astype(np.float64)).to(device),\n",
        "\t\tTensor(y).long().to(device),\n",
        "\t\tTensor(protected_attribute).long().to(device),\n",
        "\t\tTensor(is_senior).long().to(device),\n",
        "\t\tTensor(displayrandom).long().to(device),\n",
        "\t\tTensor(rank).long().to(device),\n",
        "\t\t)\n",
        "\n",
        "\tif args.unfair == 1:\n",
        "\t\tX = torch.hstack([X, protected_attribute.unsqueeze(dim=1)])\n",
        "\t\targs.name += \"_unfair\"\n",
        "\n",
        "\t(\n",
        "\t\tX_train,\n",
        "\t\tX_test,\n",
        "\t\ty_train,\n",
        "\t\ty_test,\n",
        "\t\tprotected_attribute_train,\n",
        "\t\tprotected_attribute_test,\n",
        "\t\tis_senior_train,\n",
        "\t\tis_senior_test,\n",
        "\t\tdisplayrandom_train,\n",
        "\t\tdisplayrandom_test,\n",
        "\t\trank_train,\n",
        "\t\trank_test,\n",
        "\t\t) = train_test_split(X, y, protected_attribute, is_senior, displayrandom, rank)\n",
        "\n",
        "\tX_extended_train = torch.hstack(\n",
        "\t\t[\n",
        "\t\t\tdisplayrandom_train.unsqueeze(1),\n",
        "\t\t\tis_senior_train.unsqueeze(1),\n",
        "\t\t\tX_train,\n",
        "\t\t\trank_train.unsqueeze(1),\n",
        "\t\t\t]\n",
        "\t\t)\n",
        "\tX_extended_test = torch.hstack(\n",
        "\t\t[displayrandom_test.unsqueeze(1), is_senior_test.unsqueeze(1), X_test, rank_test.unsqueeze(1)]\n",
        "\t\t)\n",
        "\tcategorical_features_cardinalities_extended = {\n",
        "\t\tkey + 2: value for key, value in categorical_features_cardinalities.items()\n",
        "\t\t}\n",
        "\tcategorical_features_cardinalities_extended[0] = 2  # cardinality for displayrandom\n",
        "\tcategorical_features_cardinalities_extended[1] = 2  # cardinality for is_senior\n",
        "\n",
        "\timpression_test = X_test[:, 1]\n",
        "\tproduct_test = X_test[:, 2]\n",
        "\n",
        "\tfair_indicator = (\n",
        "\t\ttorch.bernoulli(fair_fraction * torch.ones(size=y_train.shape)).to(torch.int).to(device)\n",
        "\t)\n",
        "\n",
        "\tdata_train = JobDataset(X_extended_train, y_train, protected_attribute_train, fair_indicator)\n",
        "\n",
        "\n",
        "\t###############\n",
        "\t#### DUMMY ####\n",
        "\t###############\n",
        "\n",
        "\tif args.dummy:\n",
        "\t\tprint(\"\\n RUNNING DUMMY \\n\")\n",
        "\t\tdummy = Learner(DummyClassifier(), device=device)\n",
        "\t\tfor _ in range(N_EPOCHS):\n",
        "\t\t\tdummy.fit(x=X_extended_train, y=y_train, a=protected_attribute_train, batch_size=batch_size)\n",
        "\n",
        "\t\ty_pred = dummy(X_extended_test)\n",
        "\t\tp = torch.softmax(y_pred, dim=1)\n",
        "\t\tres_pred_df = pd.concat(\n",
        "\t\t\t[\n",
        "\t\t\t\tres_pred_df,\n",
        "\t\t\t\tpd.DataFrame(\n",
        "\t\t\t\t\t{\n",
        "\t\t\t\t\t\t\"prob_test\": p[:, 1].detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"y_test\": y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"a_test\": protected_attribute_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"s_test\": is_senior_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"displayrandom_test\": displayrandom_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"impression_id_test\": impression_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"product_id_test\": product_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t.reset_index(names=\"obs_index\")\n",
        "\t\t\t\t.assign(model=\"Dummy\", fairness_multiplier=None, fairness_fraction=None),\n",
        "\t\t\t\t]\n",
        "\t\t\t)\n",
        "\t\tres_pred_df.to_csv((\"output/SINGLE_pred\" + args.name + \".csv\"), mode=\"w+\")\n",
        "\n",
        "\t\tprint(\n",
        "\t\t\t\"DUMMY: NLLH: %.5f DP: %.5f UTILITY: %.5f UTILITY_P: %.5f UTILITY_P_FAIR: %.5f AU-ROC: %.5f AVG-P-SCORE: %.5f \\n\"\n",
        "\t\t\t% (\n",
        "\t\t\t\tnn.CrossEntropyLoss()(y_pred, y_test).item(),\n",
        "\t\t\t\tdemographic_parity(\n",
        "\t\t\t\t\tp,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\tis_senior_test,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility(\n",
        "\t\t\t\t\tp,\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility_product(\n",
        "\t\t\t\t\tp,\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\tproduct_test,\n",
        "\t\t\t\t\tunbiased_ratio=False,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility_product(\n",
        "\t\t\t\t\tp,\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\tproduct_test,\n",
        "\t\t\t\t\tunbiased_ratio=True,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\troc_auc_score(\n",
        "\t\t\t\t\ty_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\ty_score=p[:, 1].detach().cpu().numpy(),\n",
        "\t\t\t\t\taverage=\"macro\",\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\taverage_precision_score(\n",
        "\t\t\t\t\ty_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\ty_score=p[:, 1].detach().cpu().numpy(),\n",
        "\t\t\t\t\taverage=\"macro\",\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\t)\n",
        "\t\t\t)\n",
        "\n",
        "\tif args.lr_fair == 0:\n",
        "\t\t\tprint(\"\\n RUNNING LOGISTIC REGRESSION \\n\")\n",
        "\t\t\tdef objective(trial):\n",
        "\t\t\t\t\t(\n",
        "\t\t\t\t\t\t\tX_train_train,\n",
        "\t\t\t\t\t\t\tX_val,\n",
        "\t\t\t\t\t\t\ty_train_train,\n",
        "\t\t\t\t\t\t\ty_val,\n",
        "\t\t\t\t\t\t\tprotected_attribute_train_train,\n",
        "\t\t\t\t\t\t\tprotected_attribute_val,\n",
        "\t\t\t\t\t\t\tis_senior_train_train,\n",
        "\t\t\t\t\t\t\tis_senior_val,\n",
        "\t\t\t\t\t\t\tdisplayrandom_train_train,\n",
        "\t\t\t\t\t\t\tdisplayrandom_val,\n",
        "\t\t\t\t\t\t\trank_train_train,\n",
        "\t\t\t\t\t\t\trank_val,\n",
        "\t\t\t\t\t) = train_test_split(X_train, y_train, protected_attribute_train, is_senior_train, displayrandom_train, rank_train)\n",
        "\t\t\t\t\tX_extended_train_train = torch.hstack(\n",
        "\t\t\t\t\t\t\t[\n",
        "\t\t\t\t\t\t\t\t\tdisplayrandom_train_train.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\t\tis_senior_train_train.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\t\tX_train_train,\n",
        "\t\t\t\t\t\t\t\t\trank_train_train.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t]\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t\tX_extended_val = torch.hstack(\n",
        "\t\t\t\t\t\t\t[\n",
        "\t\t\t\t\t\t\t\t\tdisplayrandom_val.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\t\tis_senior_val.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\t\tX_val,\n",
        "\t\t\t\t\t\t\t\t\trank_val.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t]\n",
        "\t\t\t\t\t)\n",
        "\n",
        "\t\t\t\t\temb_size = trial.suggest_int('emb_size',4,5)\n",
        "\t\t\t\t\tlearning_rate = trial.suggest_float('learning_rate',1e-4, 1e-2,log=True)\n",
        "\t\t\t\t\tweight_decay = trial.suggest_float('weight_decay',1e-6, 1e-4,log=True)\n",
        "\t\t\t\t\tscheduler_step_size = trial.suggest_int('scheduler_step_size',20,N_EPOCHS)\n",
        "\t\t\t\t\tscheduler_gamma = trial.suggest_float('scheduler_gamma',1e-2,1,log=True)\n",
        "\n",
        "\t\t\t\t\tlr = Learner(\n",
        "\t\t\t\t\t\t\tLogisticRegression(X_extended_train_train.shape[1], categorical_features_cardinalities_extended, emb_size),\n",
        "\t\t\t\t\t\t\tdevice=device,\n",
        "\t\t\t\t\t\t\tscheduler_step_size=scheduler_step_size,\n",
        "\t\t\t\t\t\t\tscheduler_gamma=scheduler_gamma,\n",
        "\t\t\t\t\t\t\tlr=learning_rate,\n",
        "\t\t\t\t\t\t\tweight_decay=weight_decay\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t\tfor _ in range(N_EPOCHS):\n",
        "\t\t\t\t\t\t\tif _ * batch_size > N_TRAIN_EXAMPLES:\n",
        "\t\t\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\t\t\tlr.fit(\n",
        "\t\t\t\t\t\t\t\t\tx = X_extended_train_train,\n",
        "\t\t\t\t\t\t\t\t\ty = y_train_train,\n",
        "\t\t\t\t\t\t\t\t\ta = protected_attribute_train_train,\n",
        "\t\t\t\t\t\t\t\t\tbatch_size = batch_size,\n",
        "\t\t\t\t\t\t\t)\n",
        "\t\t\t\t\t\t\tlr.scheduler_step()\n",
        "\n",
        "\t\t\t\t\t\t\ty_pred = lr(X_extended_val)\n",
        "\t\t\t\t\t\t\tintermediate_value = nn.CrossEntropyLoss()(y_pred, y_val).item()\n",
        "\t\t\t\t\t\t\ttrial.report(intermediate_value, _)\n",
        "\t\t\t\t\t\t\tif trial.should_prune():\n",
        "\t\t\t\t\t\t\t\t\traise optuna.TrialPruned()\n",
        "\n",
        "\t\t\t\t\ty_pred = lr(X_extended_val)\n",
        "\t\t\t\t\treturn nn.CrossEntropyLoss()(y_pred, y_val).item()\n",
        "\n",
        "\t\t\tstudy = optuna.create_study(direction='minimize')\n",
        "\t\t\tstudy.optimize(objective, n_trials=n_trials)\n",
        "\t\t\toptimal = study.best_trial\n",
        "\t\t\tpd.DataFrame(optimal.params, index=[sim]).to_csv(\n",
        "\t\t\t\t\t(\"output/model_hyperparameters/LR_opt_params\" + args.name + \".csv\"),\n",
        "\t\t\t\t\tmode='a', header=not (\"output/model_hyperparameters/LR_opt_params\" + args.name + \".csv\")\n",
        "\t\t\t)\n",
        "\t\t\tresults_regular_df = pd.DataFrame()\n",
        "\t\t\t# Fit on all training data\n",
        "\t\t\tlr = Learner(\n",
        "\t\t\t\t\tLogisticRegression(\n",
        "\t\t\t\t\t\t\tX_extended_train.shape[1],\n",
        "\t\t\t\t\t\t\tcategorical_features_cardinalities_extended,\n",
        "\t\t\t\t\t\t\toptimal.params[\"emb_size\"],\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\t\tdevice=device,\n",
        "\t\t\t\t\tscheduler_step_size=optimal.params['scheduler_step_size'],\n",
        "\t\t\t\t\tscheduler_gamma=optimal.params['scheduler_gamma'],\n",
        "\t\t\t\t\tlr=optimal.params[\"learning_rate\"],\n",
        "\t\t\t\t\tweight_decay=optimal.params[\"weight_decay\"],\n",
        "\t\t\t)\n",
        "\t\t\tfor _ in range(N_EPOCHS):\n",
        "\t\t\t\t\tlr.fit(\n",
        "\t\t\t\t\t\t\tx=X_extended_train,\n",
        "\t\t\t\t\t\t\ty=y_train,\n",
        "\t\t\t\t\t\t\ta=protected_attribute_train,\n",
        "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t\tlr.scheduler_step()\n",
        "\n",
        "\t\t\tres_pred_df = pd.concat(\n",
        "\t\t\t[\n",
        "\t\t\t\tres_pred_df,\n",
        "\t\t\t\tpd.DataFrame(\n",
        "\t\t\t\t\t{\n",
        "\t\t\t\t\t\t\"prob_test\": p[:, 1].detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"y_test\": y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"a_test\": protected_attribute_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"s_test\": is_senior_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"displayrandom_test\": displayrandom_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"impression_id_test\": impression_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"product_id_test\": product_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t.reset_index(names=\"obs_index\")\n",
        "\t\t\t\t.assign(\n",
        "\t\t\t\t\tmodel=\"LR\", fairness_multiplier=l2_fair_multiplier, fairness_fraction=fair_fraction\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\t]\n",
        "\t\t\t)\n",
        "\n",
        "\t\t\t# Intermediate save\n",
        "\t\t\tres_pred_df.to_csv(('output/SINGLE_PRED_LR' + args.name + '.csv'), mode='w+')\n",
        "\t\t\tprint(\n",
        "\t\t\t\"\\n LR: NLLH: %.5f DP: %.5f UTILITY: %.5f UTILITY_P: %.5f UTILITY_P_FAIR: %.5f AU-ROC: %.5f AVG-P-SCORE: %.5f \\n\"\n",
        "\t\t\t% (\n",
        "\t\t\t\tlog_loss(y_test.detach().cpu().numpy(), prob_test),\n",
        "\t\t\t\tdemographic_parity(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\tis_senior_test,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility_product(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\tproduct_test,\n",
        "\t\t\t\t\tunbiased_ratio=False,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility_product(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\tproduct_test,\n",
        "\t\t\t\t\tunbiased_ratio=True,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\troc_auc_score(\n",
        "\t\t\t\t\ty_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\ty_score=prob_test[:, 1],\n",
        "\t\t\t\t\taverage=\"macro\",\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\taverage_precision_score(\n",
        "\t\t\t\t\ty_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\ty_score=prob_test[:, 1],\n",
        "\t\t\t\t\taverage=\"macro\",\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\t)\n",
        "\t\t\t)\n",
        "\n",
        "\n",
        "\t# FAIR LOGISTIC REGRESSION\n",
        "\tif args.lr_fair:\n",
        "\n",
        "\t\tprint(f\"\\n RUNNING FAIR LOGISTIC REGRESSION with lambda {l2_fair_multiplier} and frac {fair_fraction} \\n\")\n",
        "\n",
        "\t\t# Define objective for hyperparameter search with optuna\n",
        "\t\tdef objective(trial):\n",
        "\t\t\t\t(\n",
        "\t\t\t\t\t\tX_train_train,\n",
        "\t\t\t\t\t\tX_val,\n",
        "\t\t\t\t\t\ty_train_train,\n",
        "\t\t\t\t\t\ty_val,\n",
        "\t\t\t\t\t\tprotected_attribute_train_train,\n",
        "\t\t\t\t\t\tprotected_attribute_val,\n",
        "\t\t\t\t\t\tis_senior_train_train,\n",
        "\t\t\t\t\t\tis_senior_val,\n",
        "\t\t\t\t\t\tdisplayrandom_train_train,\n",
        "\t\t\t\t\t\tdisplayrandom_val,\n",
        "\t\t\t\t\t\trank_train_train,\n",
        "\t\t\t\t\t\trank_val,\n",
        "\t\t\t\t) = train_test_split(\n",
        "\t\t\t\t\t\tX_train,\n",
        "\t\t\t\t\t\ty_train,\n",
        "\t\t\t\t\t\tprotected_attribute_train,\n",
        "\t\t\t\t\t\tis_senior_train,\n",
        "\t\t\t\t\t\tdisplayrandom_train,\n",
        "\t\t\t\t\t\trank_train,\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\t\t# Create extended feature matrices\n",
        "\t\t\t\tX_extended_train_train = torch.hstack(\n",
        "\t\t\t\t\t\t[\n",
        "\t\t\t\t\t\t\t\tdisplayrandom_train_train.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\tis_senior_train_train.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\tX_train_train,\n",
        "\t\t\t\t\t\t\t\trank_train_train.unsqueeze(1),\n",
        "\t\t\t\t\t\t]\n",
        "\t\t\t\t)\n",
        "\t\t\t\tX_extended_val = torch.hstack(\n",
        "\t\t\t\t\t\t[\n",
        "\t\t\t\t\t\t\t\tdisplayrandom_val.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\tis_senior_val.unsqueeze(1),\n",
        "\t\t\t\t\t\t\t\tX_val,\n",
        "\t\t\t\t\t\t\t\trank_val.unsqueeze(1),\n",
        "\t\t\t\t\t\t]\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\t\t# Create a fair indicator tensor based on the fair_fraction parameter\n",
        "\t\t\t\tfair_indicator = (\n",
        "\t\t\t\t\t\ttorch.bernoulli(fair_fraction * torch.ones(size=y_train_train.shape))\n",
        "\t\t\t\t\t\t.to(torch.int)\n",
        "\t\t\t\t\t\t.to(device)\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\t\t# Suggest hyperparameters using optuna\n",
        "\t\t\t\temb_size = trial.suggest_int(\"emb_size\", 4, 8)\n",
        "\t\t\t\tlearning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "\t\t\t\tweight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
        "\n",
        "\t\t\t\t# Create the Learner wrapping the logistic regression model\n",
        "\t\t\t\tfair_lr = Learner(\n",
        "\t\t\t\t\t\tLogisticRegression(\n",
        "\t\t\t\t\t\t\t\tX_extended_train_train.shape[1],\n",
        "\t\t\t\t\t\t\t\tcategorical_features_cardinalities_extended,\n",
        "\t\t\t\t\t\t\t\tembedding_size=emb_size,\n",
        "\t\t\t\t\t\t),\n",
        "\t\t\t\t\t\tdevice=device,\n",
        "\t\t\t\t\t\tbasename=\"L2 FAIR\",\n",
        "\t\t\t\t\t\tlr=learning_rate,\n",
        "\t\t\t\t\t\tweight_decay=weight_decay,\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\t\t# Train on mini-batches up to N_TRAIN_EXAMPLES\n",
        "\t\t\t\tfor _ in range(N_EPOCHS):\n",
        "\t\t\t\t\t\tif _ * batch_size > N_TRAIN_EXAMPLES:\n",
        "\t\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\t\tfair_lr.fit(\n",
        "\t\t\t\t\t\t\t\tx=X_extended_train_train,\n",
        "\t\t\t\t\t\t\t\ty=y_train_train,\n",
        "\t\t\t\t\t\t\t\ta=protected_attribute_train_train,\n",
        "\t\t\t\t\t\t\t\tpenalty_fun=l2_conditional_independence_penalty,\n",
        "\t\t\t\t\t\t\t\tpenalty_multiplier=l2_fair_multiplier,\n",
        "\t\t\t\t\t\t\t\tfair_indicator=fair_indicator,\n",
        "\t\t\t\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\t\t)\n",
        "\t\t\t\ty_pred = fair_lr(X_extended_val)\n",
        "\n",
        "\t\t\t\t# Return the validation loss for optuna to minimize\n",
        "\t\t\t\treturn nn.CrossEntropyLoss()(y_pred, y_val).item()\n",
        "\n",
        "\t\t# Run optuna hyperparameter search\n",
        "\t\tstudy = optuna.create_study(direction=\"minimize\")\n",
        "\t\tstudy.optimize(objective, n_trials=n_trials)\n",
        "\t\toptimal = study.best_trial\n",
        "\n",
        "\t\t# Save optimal parameters for record keeping\n",
        "\t\tpd.DataFrame(\n",
        "\t\t\t\toptimal.params,\n",
        "\t\t\t\tindex=pd.MultiIndex.from_product([[fair_fraction], [sim]], names=[\"fair_fraction\", \"sim\"]),\n",
        "\t\t).to_csv(\n",
        "\t\t\t\t(\"output/model_hyperparameters/SINGLE_FAIR_LR_W_opt_params\" + args.name + \".csv\"),\n",
        "\t\t\t\tmode=\"a\",\n",
        "\t\t\t\theader=not (\"output/model_hyperparameters/SINGLE_FAIR_LR_W_opt_params\" + args.name + \".csv\"),\n",
        "\t\t)\n",
        "\n",
        "\t\t# Instantiate the final fair logistic regression model with the best hyperparameters\n",
        "\t\tfair_lr = Learner(\n",
        "\t\t\t\tLogisticRegression(\n",
        "\t\t\t\t\t\tX_extended_train.shape[1],\n",
        "\t\t\t\t\t\tcategorical_features_cardinalities_extended,\n",
        "\t\t\t\t\t\tembedding_size=optimal.params[\"emb_size\"],\n",
        "\t\t\t\t),\n",
        "\t\t\t\tdevice=device,\n",
        "\t\t\t\tbasename=\"L2 FAIR\",\n",
        "\t\t\t\tlr=optimal.params[\"learning_rate\"],\n",
        "\t\t\t\tweight_decay=optimal.params[\"weight_decay\"],\n",
        "\t\t)\n",
        "\n",
        "\t\t# Train on the full training set\n",
        "\t\tfor _ in range(N_EPOCHS):\n",
        "\t\t\t\tprint(\"EPOCHS: \" + str(_ + 1) + \"/\" + str(N_EPOCHS) + \"\\n\")\n",
        "\t\t\t\tfair_lr.fit(\n",
        "\t\t\t\t\t\tx=X_extended_train,\n",
        "\t\t\t\t\t\ty=y_train,\n",
        "\t\t\t\t\t\ta=protected_attribute_train,\n",
        "\t\t\t\t\t\tpenalty_fun=l2_conditional_independence_penalty,\n",
        "\t\t\t\t\t\tpenalty_multiplier=l2_fair_multiplier,\n",
        "\t\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\t\tfair_indicator=fair_indicator,\n",
        "\t\t\t\t)\n",
        "\t\t\t\twith torch.no_grad():\n",
        "\t\t\t\t\t\ttmp = fair_lr(X_extended_train)\n",
        "\t\t\t\t\t\ttmp_test = fair_lr(X_extended_test)\n",
        "\t\t\t\tprint(f\"training NLLH : {nn.CrossEntropyLoss()(tmp,y_train).item()}\")\n",
        "\t\t\t\tprint(f\"test NLLH : {nn.CrossEntropyLoss()(tmp_test,y_test).item()}\")\n",
        "\n",
        "\t\t# Compute predictions on the test set and define 'p'\n",
        "\t\ty_pred = fair_lr(X_extended_test)\n",
        "\t\tp = torch.softmax(y_pred, dim=1)  # This ensures that 'p' is defined\n",
        "\n",
        "\t\t# Concatenate predictions into the result DataFrame\n",
        "\t\tres_pred_df = pd.concat(\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t\tres_pred_df,  # Make sure res_pred_df exists (e.g., defined earlier as an empty DataFrame)\n",
        "\t\t\t\t\t\tpd.DataFrame(\n",
        "\t\t\t\t\t\t\t\t{\n",
        "\t\t\t\t\t\t\t\t\t\t\"prob_test\": p[:, 1].detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\"y_test\": y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\"a_test\": protected_attribute_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\"s_test\": is_senior_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\"displayrandom_test\": displayrandom_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\"impression_id_test\": impression_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\"product_id_test\": product_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t)\n",
        "\t\t\t\t\t\t.reset_index(names=\"obs_index\")\n",
        "\t\t\t\t\t\t.assign(\n",
        "\t\t\t\t\t\t\t\tmodel=\"LR\", fairness_multiplier=l2_fair_multiplier, fairness_fraction=fair_fraction\n",
        "\t\t\t\t\t\t),\n",
        "\t\t\t\t]\n",
        "\t\t)\n",
        "\t\tres_pred_df.to_csv((\"output/SINGLE_pred\" + args.name + \".csv\"), mode=\"w+\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t#################\n",
        "\t#### XGBOOST ####\n",
        "\t#################\n",
        "\n",
        "\tif args.xgb:\n",
        "\t\tprint(\"\\n RUNNING XGBOOST \\n\")\n",
        "\t\tcat_cols = list(categorical_features_cardinalities_extended.keys())\n",
        "\n",
        "\t\tenc_auto = TargetEncoder(target_type=\"binary\")\n",
        "\t\tenc_auto.fit(\n",
        "\t\t\tX_extended_train[:, cat_cols].detach().cpu().numpy(), y_train.detach().cpu().numpy()\n",
        "\t\t\t)\n",
        "\n",
        "\t\tdef objective(trial):\n",
        "\t\t\t(\n",
        "\t\t\t\tX_train_train,\n",
        "\t\t\t\tX_val,\n",
        "\t\t\t\ty_train_train,\n",
        "\t\t\t\ty_val,\n",
        "\t\t\t\tprotected_attribute_train_train,\n",
        "\t\t\t\tprotected_attribute_val,\n",
        "\t\t\t\tis_senior_train_train,\n",
        "\t\t\t\tis_senior_val,\n",
        "\t\t\t\tdisplayrandom_train_train,\n",
        "\t\t\t\tdisplayrandom_val,\n",
        "\t\t\t\trank_train_train,\n",
        "\t\t\t\trank_val,\n",
        "\t\t\t\t) = train_test_split(\n",
        "\t\t\t\tX_train,\n",
        "\t\t\t\ty_train,\n",
        "\t\t\t\tprotected_attribute_train,\n",
        "\t\t\t\tis_senior_train,\n",
        "\t\t\t\tdisplayrandom_train,\n",
        "\t\t\t\trank_train,\n",
        "\t\t\t\t)\n",
        "\t\t\tX_extended_train_train = torch.hstack(\n",
        "\t\t\t\t[displayrandom_train_train.unsqueeze(1), X_train_train, rank_train_train.unsqueeze(1)]\n",
        "\t\t\t\t)\n",
        "\t\t\tX_extended_val = torch.hstack(\n",
        "\t\t\t\t[displayrandom_val.unsqueeze(1), X_val, rank_val.unsqueeze(1)]\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\tmax_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
        "\t\t\tmin_child_weight = trial.suggest_float(\"min_child_weight\", 0.0001, 100, log=True)\n",
        "\t\t\tsubsample = trial.suggest_float(\"subsample\", 0.5, 1)\n",
        "\t\t\tlearning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1, log=True)\n",
        "\t\t\tcolsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1)\n",
        "\t\t\treg_lambda = trial.suggest_float(\"reg_lambda\", 0.1, 10, log=True)\n",
        "\t\t\tgamma = trial.suggest_float(\"gamma\", 0.001, 100, log=True)\n",
        "\n",
        "\t\t\tscale_pos_weight = (\n",
        "\t\t\t\t(torch.sum(y_train_train < 1) / torch.sum(y_train_train > 0)).detach().cpu().numpy()\n",
        "\t\t\t)\n",
        "\n",
        "\t\t\tX_xgb_train = np.hstack(\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\tenc_auto.transform(X_extended_train_train[:, cat_cols].detach().cpu().numpy()),\n",
        "\t\t\t\t\tX_extended_train_train[:, (max(cat_cols) + 1) :].detach().cpu().numpy(),\n",
        "\t\t\t\t\t]\n",
        "\t\t\t\t)\n",
        "\t\t\tX_xgb_val = np.hstack(\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\tenc_auto.transform(X_extended_val[:, cat_cols].detach().cpu().numpy()),\n",
        "\t\t\t\t\tX_extended_val[:, (max(cat_cols) + 1) :].detach().cpu().numpy(),\n",
        "\t\t\t\t\t]\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\tmodel_xgb = xgb.XGBClassifier(\n",
        "\t\t\t\tscale_pos_weight=scale_pos_weight,\n",
        "\t\t\t\ttree_method=xgb_tree_method,\n",
        "\t\t\t\tdevice=xgb_device,\n",
        "\t\t\t\tmax_depth=max_depth,\n",
        "\t\t\t\tmin_child_weight=min_child_weight,\n",
        "\t\t\t\tsubsample=subsample,\n",
        "\t\t\t\tlearning_rate=learning_rate,\n",
        "\t\t\t\tgamma=gamma,\n",
        "\t\t\t\tcolsample_bytree=colsample_bytree,\n",
        "\t\t\t\treg_lambda=reg_lambda,\n",
        "\t\t\t\t)\n",
        "\t\t\tmodel_xgb.fit(X_xgb_train, y_train_train.detach().cpu().numpy())\n",
        "\t\t\tprob_val = model_xgb.predict_proba(X_xgb_val)\n",
        "\t\t\treturn log_loss(y_val.detach().cpu().numpy(), prob_val)\n",
        "\n",
        "\t\tstudy = optuna.create_study(direction=\"minimize\")\n",
        "\t\tstudy.optimize(objective, n_trials=n_trials)\n",
        "\t\toptimal = study.best_trial\n",
        "\t\tpd.DataFrame(optimal.params, index=[sim]).to_csv(\n",
        "\t\t\t(\"output/model_hyperparameters/XGBoost_opt_params\" + args.name + \".csv\"),\n",
        "\t\t\tmode=\"a\",\n",
        "\t\t\theader=not (\n",
        "\t\t\t\t\"output/model_hyperparameters/XGBoost_opt_params\" + args.name + \".csv\"\n",
        "\t\t\t\t),\n",
        "\t\t\t)\n",
        "\t\tscale_pos_weight = (torch.sum(y_train < 1) / torch.sum(y_train > 0)).detach().cpu().numpy()\n",
        "\t\tX_xgb_train = np.hstack(\n",
        "\t\t\t[\n",
        "\t\t\t\tenc_auto.transform(X_extended_train[:, cat_cols].detach().cpu().numpy()),\n",
        "\t\t\t\tX_extended_train[:, (max(cat_cols) + 1) :].detach().cpu().numpy(),\n",
        "\t\t\t\t]\n",
        "\t\t\t)\n",
        "\t\tX_xgb_test = np.hstack(\n",
        "\t\t\t[\n",
        "\t\t\t\tenc_auto.transform(X_extended_test[:, cat_cols].detach().cpu().numpy()),\n",
        "\t\t\t\tX_extended_test[:, (max(cat_cols) + 1) :].detach().cpu().numpy(),\n",
        "\t\t\t\t]\n",
        "\t\t\t)\n",
        "\t\tmodel_xgb = xgb.XGBClassifier(\n",
        "\t\t\tscale_pos_weight=scale_pos_weight,\n",
        "\t\t\ttree_method=xgb_tree_method,\n",
        "\t\t\tdevice=xgb_device,\n",
        "\t\t\tmax_depth=optimal.params[\"max_depth\"],\n",
        "\t\t\tmin_child_weight=optimal.params[\"min_child_weight\"],\n",
        "\t\t\tgamma=optimal.params[\"gamma\"],\n",
        "\t\t\tsubsample=optimal.params[\"subsample\"],\n",
        "\t\t\tlearning_rate=optimal.params[\"learning_rate\"],\n",
        "\t\t\tcolsample_bytree=optimal.params[\"colsample_bytree\"],\n",
        "\t\t\treg_lambda=optimal.params[\"reg_lambda\"],\n",
        "\t\t\t)\n",
        "\t\tmodel_xgb.fit(X_extended_train.detach().cpu().numpy(), y_train.detach().cpu().numpy())\n",
        "\n",
        "\t\tif args.unfair == 0:\n",
        "\t\t\tmodel_xgb.save_model((\"output/XGB_single_fit.model\"))\n",
        "\t\telse:\n",
        "\t\t\tmodel_xgb.save_model((\"output/XGB_single_fit_unfair.model\"))\n",
        "\n",
        "\t\tprob_test = model_xgb.predict_proba(X_extended_test.detach().cpu().numpy())\n",
        "\n",
        "\t\tres_pred_df = pd.concat(\n",
        "\t\t\t[\n",
        "\t\t\t\tres_pred_df,\n",
        "\t\t\t\tpd.DataFrame(\n",
        "\t\t\t\t\t{\n",
        "\t\t\t\t\t\t\"prob_test\": prob_test[:, 1],\n",
        "\t\t\t\t\t\t\"y_test\": y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"a_test\": protected_attribute_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"s_test\": is_senior_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"displayrandom_test\": displayrandom_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"impression_id_test\": impression_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t\"product_id_test\": product_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t.reset_index(names=\"obs_index\")\n",
        "\t\t\t\t.assign(model=\"XGB\", fairness_multiplier=None, fairness_fraction=None),\n",
        "\t\t\t\t]\n",
        "\t\t\t)\n",
        "\t\tres_pred_df.to_csv((\"output/SINGLE_pred\" + args.name + \".csv\"), mode=\"w+\")\n",
        "\n",
        "\t\tprint(\n",
        "\t\t\t\"\\nXGBoost: NLLH: %.5f DP: %.5f UTILITY: %.5f UTILITY_P: %.5f UTILITY_P_FAIR: %.5f AU-ROC: %.5f AVG-P-SCORE: %.5f \\n\"\n",
        "\t\t\t% (\n",
        "\t\t\t\tlog_loss(y_test.detach().cpu().numpy(), prob_test),\n",
        "\t\t\t\tdemographic_parity(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\tis_senior_test,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility_product(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\tproduct_test,\n",
        "\t\t\t\t\tunbiased_ratio=False,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\tutility_product(\n",
        "\t\t\t\t\tTensor(prob_test.astype(np.float64)).to(device),\n",
        "\t\t\t\t\ty_test,\n",
        "\t\t\t\t\tprotected_attribute_test,\n",
        "\t\t\t\t\timpression_test,\n",
        "\t\t\t\t\tdisplayrandom_test,\n",
        "\t\t\t\t\tproduct_test,\n",
        "\t\t\t\t\tunbiased_ratio=True,\n",
        "\t\t\t\t\t).item(),\n",
        "\t\t\t\troc_auc_score(\n",
        "\t\t\t\t\ty_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\ty_score=prob_test[:, 1],\n",
        "\t\t\t\t\taverage=\"macro\",\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\taverage_precision_score(\n",
        "\t\t\t\t\ty_true=y_test.detach().cpu().numpy(),\n",
        "\t\t\t\t\ty_score=prob_test[:, 1],\n",
        "\t\t\t\t\taverage=\"macro\",\n",
        "\t\t\t\t\t),\n",
        "\t\t\t\t)\n",
        "\t\t\t)\n",
        "\n",
        "\n",
        "\t# Final save\n",
        "\tres_pred_df.to_csv((\"output/SINGLE_pred\" + args.name + \".csv\"), mode=\"w+\")\n",
        "\t\t# Your existing script logic goes\n",
        "\t\t# Load data, process, train models, save results, etc.\n",
        "\n",
        "\tprint(f\"Experiment {args.name} completed.\\n\")\n"
      ],
      "metadata": {
        "id": "_iM-Wrbhku1m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "# Define a list of different experiment settings\n",
        "experiment_configs = [\n",
        "\t# Namespace(batch=2048, lambda_fair=0.1, data_frac=1.0, ntrial=1, dummy=1, lr_fair=0, xgb=0, name=\"DUMMY\", unfair=0, data=\"fairjob.csv.gz\"),\n",
        "\t# Namespace(batch=2048, lambda_fair=3.0, data_frac=1.0, ntrial=1, dummy=0, lr_fair=1, xgb=0, name=\"LR_FAIR\", unfair=0, data=\"fairjob.csv.gz\"),\n",
        "\t# Namespace(batch=2048, lambda_fair=0.1, data_frac=1.0, ntrial=1, dummy=0, lr_fair=0, xgb=1, name=\"XGB_UNAWARE\", unfair=0, data=\"fairjob.csv.gz\"),\n",
        "\t# Namespace(batch=2048, lambda_fair=0.1, data_frac=1.0, ntrial=1, dummy=0, lr_fair=0, xgb=1, name=\"XGB_UNFAIR\", unfair=1, data=\"fairjob.csv.gz\"),\n",
        "\t]\n",
        "\n",
        "# Loop through and execute each experiment\n",
        "for args in experiment_configs:\n",
        "\tprint(f\"\\n=== Running Experiment: {args.name} ===\\n\")\n",
        "\n",
        "\t# Call your main script logic rectly use your existing code with args)\n",
        "\t# This assumes that your script is inside a function named `run_experiment(args)`\n",
        "\trun_experiment(args)"
      ],
      "metadata": {
        "id": "OyJETFcElFJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- 1. Define the Gradient Reversal Layer ---\n",
        "class GradientReversal(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.clone()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # Reverse the gradient and scale it by lambda_\n",
        "        return -ctx.lambda_ * grad_output, None\n",
        "\n",
        "def grad_reverse(x, lambda_=1.0):\n",
        "    return GradientReversal.apply(x, lambda_)\n",
        "\n",
        "# --- 2. Define the AFN Model ---\n",
        "class AFNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, adv_hidden_dim, num_protected, dropout_rate=0.3):\n",
        "        super(AFNModel, self).__init__()\n",
        "\n",
        "        # --- Deeper Shared Feature Extractor with Dropout ---\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.BatchNorm1d(hidden_dim)\n",
        "        )\n",
        "\n",
        "        # --- Main Classifier (Head) with Dropout ---\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # --- Adversarial Network (Deeper) with Dropout ---\n",
        "        self.adversary = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, adv_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.BatchNorm1d(adv_hidden_dim),\n",
        "\n",
        "            nn.Linear(adv_hidden_dim, adv_hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(adv_hidden_dim // 2, num_protected)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lambda_adv=1.0):\n",
        "        features = self.feature_extractor(x)\n",
        "        logits = self.classifier(features)\n",
        "        reversed_features = grad_reverse(features, lambda_adv)\n",
        "        adv_logits = self.adversary(reversed_features)\n",
        "        return logits, adv_logits\n",
        "\n",
        "# --- 3. Device Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- 4. Data Loading ---\n",
        "# Use your own load_data() function here.\n",
        "# Expected return: (X, y, protected_attribute, is_senior, displayrandom, rank, categorical_features_cardinalities)\n",
        "(X, y, protected_attribute, is_senior, displayrandom, rank, categorical_features_cardinalities) = load_data(DATA_SIZE, \"fairjob.csv.gz\")\n",
        "\n",
        "# Ensure features are float32 to match the model's parameters\n",
        "X = X.astype(np.float32)\n",
        "\n",
        "# Convert to torch tensors and send to device.\n",
        "X_tensor = torch.tensor(X).to(device)\n",
        "y_tensor = torch.tensor(y).long().to(device)\n",
        "protected_tensor = torch.tensor(protected_attribute).long().to(device)\n",
        "\n",
        "# --- Split Data into Train and Test Sets and Print Class Balances ---\n",
        "X_train, X_test, y_train, y_test, protected_train, protected_test = train_test_split(\n",
        "    X_tensor, y_tensor, protected_tensor, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Train class balance:\", np.bincount(y_train.cpu().numpy()))\n",
        "print(\"Test class balance:\", np.bincount(y_test.cpu().numpy()))\n",
        "\n",
        "# --- 5. Initialize the AFN Model and Training Components ---\n",
        "input_dim = X_tensor.shape[1]\n",
        "hidden_dim = 32      # Adjust as needed\n",
        "adv_hidden_dim = 16   # Adjust as needed\n",
        "num_classes = 2       # Assuming binary classification for main task\n",
        "num_protected = 2     # Assuming binary protected attribute\n",
        "\n",
        "afn_model = AFNModel(input_dim, hidden_dim, num_classes, adv_hidden_dim, num_protected).to(device)\n",
        "optimizer = optim.Adam(afn_model.parameters(), lr=1e-5)\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "criterion_adv = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "lambda_adv = 0.5 # Weight for gradient reversal (adjust as needed)\n",
        "\n",
        "print(\"Starting AFN training with loaded data...\\n\")\n",
        "for epoch in range(num_epochs):\n",
        "    afn_model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass using training data\n",
        "    logits, adv_logits = afn_model(X_train, lambda_adv=lambda_adv)\n",
        "\n",
        "    # Compute the main task loss and adversary loss\n",
        "    loss_cls = criterion_cls(logits, y_train)\n",
        "    loss_adv = criterion_adv(adv_logits, protected_train)\n",
        "\n",
        "    total_loss = loss_cls + loss_adv\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Total Loss: {total_loss.item():.4f} | CLS Loss: {loss_cls.item():.4f} | ADV Loss: {loss_adv.item():.4f}\")\n",
        "\n",
        "# --- 6. Evaluation ---\n",
        "afn_model.eval()\n",
        "with torch.no_grad():\n",
        "    logits, _ = afn_model(X_test, lambda_adv=0.0)  # Disable gradient reversal for inference\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "probs_np = probabilities.cpu().detach().numpy()\n",
        "y_np = y_test.cpu().detach().numpy()\n",
        "predicted_labels = (probs_np[:, 1] > 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_np, predicted_labels)\n",
        "roc_auc = roc_auc_score(y_np, probs_np[:, 1])\n",
        "nllh = log_loss(y_np, probs_np)\n",
        "avg_precision = average_precision_score(y_np, probs_np[:, 1])\n",
        "cls_report = classification_report(y_np, predicted_labels)\n",
        "conf_matrix = confusion_matrix(y_np, predicted_labels)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Log Loss (NLLH): {nllh:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "print(f\"Average Precision (PR AUC): {avg_precision:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(cls_report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN9n1wUyS40_",
        "outputId": "56c1e33a-4c06-4f1d-d804-fe0b85c5e17c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train class balance: [851730   6050]\n",
            "Test class balance: [213007   1439]\n",
            "Starting AFN training with loaded data...\n",
            "\n",
            "Epoch 1/10 | Total Loss: 1.6334 | CLS Loss: 0.9023 | ADV Loss: 0.7311\n",
            "Epoch 2/10 | Total Loss: 1.6323 | CLS Loss: 0.9023 | ADV Loss: 0.7301\n",
            "Epoch 3/10 | Total Loss: 1.6328 | CLS Loss: 0.9020 | ADV Loss: 0.7308\n",
            "Epoch 4/10 | Total Loss: 1.6327 | CLS Loss: 0.9023 | ADV Loss: 0.7304\n",
            "Epoch 5/10 | Total Loss: 1.6325 | CLS Loss: 0.9020 | ADV Loss: 0.7305\n",
            "Epoch 6/10 | Total Loss: 1.6321 | CLS Loss: 0.9016 | ADV Loss: 0.7305\n",
            "Epoch 7/10 | Total Loss: 1.6325 | CLS Loss: 0.9020 | ADV Loss: 0.7305\n",
            "Epoch 8/10 | Total Loss: 1.6328 | CLS Loss: 0.9017 | ADV Loss: 0.7312\n",
            "Epoch 9/10 | Total Loss: 1.6317 | CLS Loss: 0.9017 | ADV Loss: 0.7300\n",
            "Epoch 10/10 | Total Loss: 1.6307 | CLS Loss: 0.9005 | ADV Loss: 0.7302\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.9852\n",
            "Log Loss (NLLH): 0.8271\n",
            "ROC-AUC: 0.9846\n",
            "Average Precision (PR AUC): 0.7083\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9999     0.9852     0.9925   213007\n",
            "           1     0.3118     0.9924     0.4743     1439\n",
            "\n",
            "    accuracy                         0.9852   214446\n",
            "   macro avg     0.6559     0.9888     0.7334   214446\n",
            "weighted avg     0.9933     0.9852     0.9881   214446\n",
            "\n",
            "Confusion Matrix:\n",
            "[[209856   3151]\n",
            " [    11   1428]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss, accuracy_score, classification_report, roc_auc_score, average_precision_score, confusion_matrix\n",
        "\n",
        "# Load the CSV file produced by your experiment\n",
        "csv_filepath = '/content/drive/MyDrive/Colab Notebooks/output/SINGLE_pred_DUMMY_lambda0.1_frac1.0.csv'\n",
        "df = pd.read_csv(csv_filepath)\n",
        "\n",
        "# Inspect the first few rows to verify the columns (for example, prob_test, y_test, etc.)\n",
        "print(df.head())\n",
        "\n",
        "# In this example, we assume:\n",
        "# - 'prob_test' holds the probability for the positive class.\n",
        "# - 'y_test' holds the true binary labels.\n",
        "#\n",
        "# If these columns represent something different (for instance, if prob_test is a serialized\n",
        "# list of probabilities for both classes), you might need to adjust accordingly.\n",
        "\n",
        "# Convert predicted probabilities into binary predictions using a threshold of 0.5\n",
        "predicted_labels = (df['prob_test'] > 0.5).astype(int)\n",
        "true_labels = df['y_test']\n",
        "\n",
        "# Calculate the log loss (negative log-likelihood)\n",
        "nllh = log_loss(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the average precision score\n",
        "avg_precision = average_precision_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Generate the classification report\n",
        "clf_report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\n📊 Evaluation Metrics:\")\n",
        "print(f\"Log Loss (NLLH): {nllh:.5f}\")\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.5f}\")\n",
        "print(f\"Average Precision Score: {avg_precision:.5f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(clf_report)\n",
        "\n",
        "print(\"\\n Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "fNxJNuPrchL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3ceae6-96a0-4569-bff0-d2088bc3063c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  model  fairness_multiplier  fairness_fraction  obs_index  \\\n",
            "0           0  Dummy                  NaN                NaN          0   \n",
            "1           1  Dummy                  NaN                NaN          1   \n",
            "2           2  Dummy                  NaN                NaN          2   \n",
            "3           3  Dummy                  NaN                NaN          3   \n",
            "4           4  Dummy                  NaN                NaN          4   \n",
            "\n",
            "   prob_test  y_test  a_test  s_test  displayrandom_test  impression_id_test  \\\n",
            "0   0.500445       0       0       1                   0             31937.0   \n",
            "1   0.500445       0       0       0                   0            190315.0   \n",
            "2   0.500445       0       1       0                   0            112057.0   \n",
            "3   0.500445       1       0       1                   0            145127.0   \n",
            "4   0.500445       0       0       1                   0            200354.0   \n",
            "\n",
            "   product_id_test  \n",
            "0          19986.0  \n",
            "1          29344.0  \n",
            "2           6599.0  \n",
            "3           2086.0  \n",
            "4           1325.0  \n",
            "\n",
            "📊 Evaluation Metrics:\n",
            "Log Loss (NLLH): 0.69402\n",
            "Accuracy: 0.00695\n",
            "ROC-AUC: 0.50000\n",
            "Average Precision Score: 0.00695\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00    212956\n",
            "           1       0.01      1.00      0.01      1490\n",
            "\n",
            "    accuracy                           0.01    214446\n",
            "   macro avg       0.00      0.50      0.01    214446\n",
            "weighted avg       0.00      0.01      0.00    214446\n",
            "\n",
            "\n",
            " Confusion Matrix:\n",
            "[[     0 212956]\n",
            " [     0   1490]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss, accuracy_score, classification_report, roc_auc_score, average_precision_score, confusion_matrix\n",
        "\n",
        "# Load the CSV file produced by your experiment\n",
        "csv_filepath = '/content/drive/MyDrive/Colab Notebooks/output/SINGLE_pred_LR_FAIR_lambda3.0_frac1.0.csv'\n",
        "df = pd.read_csv(csv_filepath)\n",
        "\n",
        "# Inspect the first few rows to verify the columns (for example, prob_test, y_test, etc.)\n",
        "print(df.head())\n",
        "\n",
        "# In this example, we assume:\n",
        "# - 'prob_test' holds the probability for the positive class.\n",
        "# - 'y_test' holds the true binary labels.\n",
        "#\n",
        "# If these columns represent something different (for instance, if prob_test is a serialized\n",
        "# list of probabilities for both classes), you might need to adjust accordingly.\n",
        "\n",
        "# Convert predicted probabilities into binary predictions using a threshold of 0.5\n",
        "predicted_labels = (df['prob_test'] > 0.5).astype(int)\n",
        "true_labels = df['y_test']\n",
        "\n",
        "# Calculate the log loss (negative log-likelihood)\n",
        "nllh = log_loss(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the average precision score\n",
        "avg_precision = average_precision_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Generate the classification report\n",
        "clf_report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\n📊 Evaluation Metrics:\")\n",
        "print(f\"Log Loss (NLLH): {nllh:.5f}\")\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.5f}\")\n",
        "print(f\"Average Precision Score: {avg_precision:.5f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(clf_report)\n",
        "\n",
        "print(\"\\n Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VqM46Sn6JUK",
        "outputId": "76db517f-c004-4ae5-eae2-0066d4b0c818"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 model  fairness_multiplier  fairness_fraction  obs_index  \\\n",
            "0           0    LR                  3.0                1.0          0   \n",
            "1           1    LR                  3.0                1.0          1   \n",
            "2           2    LR                  3.0                1.0          2   \n",
            "3           3    LR                  3.0                1.0          3   \n",
            "4           4    LR                  3.0                1.0          4   \n",
            "\n",
            "   prob_test  y_test  a_test  s_test  displayrandom_test  impression_id_test  \\\n",
            "0   0.380284       0       1       1                   0             51578.0   \n",
            "1   0.341565       0       1       1                   0            207009.0   \n",
            "2   0.308145       0       1       1                   0            116901.0   \n",
            "3   0.381440       0       0       1                   0            185461.0   \n",
            "4   0.357492       0       1       1                   0             47032.0   \n",
            "\n",
            "   product_id_test  \n",
            "0          14941.0  \n",
            "1          21752.0  \n",
            "2          37594.0  \n",
            "3          51270.0  \n",
            "4          49047.0  \n",
            "\n",
            "📊 Evaluation Metrics:\n",
            "Log Loss (NLLH): 0.44037\n",
            "Accuracy: 0.96918\n",
            "ROC-AUC: 0.70531\n",
            "Average Precision Score: 0.02218\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98    266193\n",
            "           1       0.03      0.12      0.05      1864\n",
            "\n",
            "    accuracy                           0.97    268057\n",
            "   macro avg       0.51      0.55      0.52    268057\n",
            "weighted avg       0.99      0.97      0.98    268057\n",
            "\n",
            "\n",
            " Confusion Matrix:\n",
            "[[259578   6615]\n",
            " [  1647    217]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss, accuracy_score, classification_report, roc_auc_score, average_precision_score, confusion_matrix\n",
        "\n",
        "# Load the CSV file produced by your experiment\n",
        "csv_filepath = '/content/drive/MyDrive/Colab Notebooks/output/SINGLE_pred_XGB_UNFAIR_lambda0.1_frac1.0_unfair.csv'\n",
        "df = pd.read_csv(csv_filepath)\n",
        "\n",
        "# Inspect the first few rows to verify the columns (for example, prob_test, y_test, etc.)\n",
        "print(df.head())\n",
        "\n",
        "# In this example, we assume:\n",
        "# - 'prob_test' holds the probability for the positive class.\n",
        "# - 'y_test' holds the true binary labels.\n",
        "#\n",
        "# If these columns represent something different (for instance, if prob_test is a serialized\n",
        "# list of probabilities for both classes), you might need to adjust accordingly.\n",
        "\n",
        "# Convert predicted probabilities into binary predictions using a threshold of 0.5\n",
        "predicted_labels = (df['prob_test'] > 0.5).astype(int)\n",
        "true_labels = df['y_test']\n",
        "\n",
        "# Calculate the log loss (negative log-likelihood)\n",
        "nllh = log_loss(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the average precision score\n",
        "avg_precision = average_precision_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Generate the classification report\n",
        "clf_report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\n📊 Evaluation Metrics:\")\n",
        "print(f\"Log Loss (NLLH): {nllh:.5f}\")\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.5f}\")\n",
        "print(f\"Average Precision Score: {avg_precision:.5f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(clf_report)\n",
        "\n",
        "print(\"\\n Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3COZDjH96eUk",
        "outputId": "bee92936-0cc1-439d-f2e6-efc534ee2b49"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 model  fairness_multiplier  fairness_fraction  obs_index  \\\n",
            "0           0   XGB                  NaN                NaN          0   \n",
            "1           1   XGB                  NaN                NaN          1   \n",
            "2           2   XGB                  NaN                NaN          2   \n",
            "3           3   XGB                  NaN                NaN          3   \n",
            "4           4   XGB                  NaN                NaN          4   \n",
            "\n",
            "   prob_test  y_test  a_test  s_test  displayrandom_test  impression_id_test  \\\n",
            "0   0.441504       0       0       1                   0             31937.0   \n",
            "1   0.480074       0       0       0                   0            190315.0   \n",
            "2   0.483358       0       1       0                   0            112057.0   \n",
            "3   0.557675       1       0       1                   0            145127.0   \n",
            "4   0.501188       0       0       1                   0            200354.0   \n",
            "\n",
            "   product_id_test  \n",
            "0          19986.0  \n",
            "1          29344.0  \n",
            "2           6599.0  \n",
            "3           2086.0  \n",
            "4           1325.0  \n",
            "\n",
            "📊 Evaluation Metrics:\n",
            "Log Loss (NLLH): 0.65407\n",
            "Accuracy: 0.76229\n",
            "ROC-AUC: 0.81459\n",
            "Average Precision Score: 0.04218\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86    212956\n",
            "           1       0.02      0.73      0.04      1490\n",
            "\n",
            "    accuracy                           0.76    214446\n",
            "   macro avg       0.51      0.75      0.45    214446\n",
            "weighted avg       0.99      0.76      0.86    214446\n",
            "\n",
            "\n",
            " Confusion Matrix:\n",
            "[[162381  50575]\n",
            " [   402   1088]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss, accuracy_score, classification_report, roc_auc_score, average_precision_score, confusion_matrix\n",
        "\n",
        "# Load the CSV file produced by your experiment\n",
        "csv_filepath = '/content/drive/MyDrive/Colab Notebooks/output/SINGLE_pred_XGB_UNFAIR_lambda0.1_frac1.0_unfair.csv'\n",
        "df = pd.read_csv(csv_filepath)\n",
        "\n",
        "# Inspect the first few rows to verify the columns (for example, prob_test, y_test, etc.)\n",
        "print(df.head())\n",
        "\n",
        "# In this example, we assume:\n",
        "# - 'prob_test' holds the probability for the positive class.\n",
        "# - 'y_test' holds the true binary labels.\n",
        "#\n",
        "# If these columns represent something different (for instance, if prob_test is a serialized\n",
        "# list of probabilities for both classes), you might need to adjust accordingly.\n",
        "\n",
        "# Convert predicted probabilities into binary predictions using a threshold of 0.5\n",
        "predicted_labels = (df['prob_test'] > 0.5).astype(int)\n",
        "true_labels = df['y_test']\n",
        "\n",
        "# Calculate the log loss (negative log-likelihood)\n",
        "nllh = log_loss(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Calculate the average precision score\n",
        "avg_precision = average_precision_score(true_labels, df['prob_test'])\n",
        "\n",
        "# Generate the classification report\n",
        "clf_report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\n📊 Evaluation Metrics:\")\n",
        "print(f\"Log Loss (NLLH): {nllh:.5f}\")\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.5f}\")\n",
        "print(f\"Average Precision Score: {avg_precision:.5f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(clf_report)\n",
        "\n",
        "print(\"\\n Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgI4WVFK7F5L",
        "outputId": "98491a84-41ef-4b1b-eb70-932f8438f90d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 model  fairness_multiplier  fairness_fraction  obs_index  \\\n",
            "0           0   XGB                  NaN                NaN          0   \n",
            "1           1   XGB                  NaN                NaN          1   \n",
            "2           2   XGB                  NaN                NaN          2   \n",
            "3           3   XGB                  NaN                NaN          3   \n",
            "4           4   XGB                  NaN                NaN          4   \n",
            "\n",
            "   prob_test  y_test  a_test  s_test  displayrandom_test  impression_id_test  \\\n",
            "0   0.441504       0       0       1                   0             31937.0   \n",
            "1   0.480074       0       0       0                   0            190315.0   \n",
            "2   0.483358       0       1       0                   0            112057.0   \n",
            "3   0.557675       1       0       1                   0            145127.0   \n",
            "4   0.501188       0       0       1                   0            200354.0   \n",
            "\n",
            "   product_id_test  \n",
            "0          19986.0  \n",
            "1          29344.0  \n",
            "2           6599.0  \n",
            "3           2086.0  \n",
            "4           1325.0  \n",
            "\n",
            "📊 Evaluation Metrics:\n",
            "Log Loss (NLLH): 0.65407\n",
            "Accuracy: 0.76229\n",
            "ROC-AUC: 0.81459\n",
            "Average Precision Score: 0.04218\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86    212956\n",
            "           1       0.02      0.73      0.04      1490\n",
            "\n",
            "    accuracy                           0.76    214446\n",
            "   macro avg       0.51      0.75      0.45    214446\n",
            "weighted avg       0.99      0.76      0.86    214446\n",
            "\n",
            "\n",
            " Confusion Matrix:\n",
            "[[162381  50575]\n",
            " [   402   1088]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wB206OAd7u0K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}